# -*- coding: utf-8 -*-
"""pla.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hC3gLstlaSNI3WYjWwH88QB-tE2amV9U
"""

import numpy as np
import secrets
import torch
from tqdm import tqdm
import matplotlib.pyplot as plt

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

N = 200
D = 47205
TIMES = 1000

def load_libsvm_data(file_path, num_lines=200, num_features=47205):
    data = []
    labels = []

    with open(file_path, 'r') as f:
        for i in range(N):
          line = (f.readline()).split()

          y = int(line[0])
          x = torch.zeros(num_features)

          for feature in line[1:]:
            index, value = map(float, feature.split(":"))
            x[int(index) - 1] = value  # feature index start from 1

          data.append(x)
          labels.append(y)

    return torch.stack(data), torch.tensor(labels)


def pla(data, labels, T_min):
    x_0 = torch.tensor([1], device = device)  # x[0] = 1
    w = torch.zeros(D + 1, device=device)     # w_0 = [0, 0, ... 0]
    func_w_t_norm = []                        # record ||w_t||

    consecutive_correct = 0
    target_correct = 5 * N
    updates = 0

    labels_tensor = torch.tensor(labels, dtype=torch.float64)

    while consecutive_correct < target_correct:
        # random sampling
        i = secrets.randbelow(N)              # random seed
        x_n = data[i]
        x_n = torch.cat((x_0, data[i]))
        y_n = labels_tensor[i]

        if torch.sign(torch.dot(w, x_n)) != y_n:
            consecutive_correct = 0
            updates += 1
            w += y_n * x_n

            # record ||w_t|| if times of update <= T_min
            if updates <= T_min:
                func_w_t_norm.append(int(torch.norm(w)))

        else:
            consecutive_correct += 1

    T_min = min(T_min, updates)

    return updates, T_min, func_w_t_norm


# def test_pla(data, labels, w):
#     labels_tensor = torch.tensor(labels, dtype=torch.float64)

#     for _ in range(5*N):
#         i = secrets.randbelow(N)
#         x_n = data[i]
#         y_n = labels_tensor[i]

#         if torch.sign(torch.dot(w, x_n)) != y_n:
#             return False

#     return True

def experiments(data, labels):
    T_min = float('inf')
    updates_list = []
    func_w_t_norm_list =[]

    for _ in tqdm(range(TIMES), desc="Running PLA experiments"):
        updates, T_min, func_w_t_norm = pla(data, labels, T_min)
        updates_list.append(updates)
        func_w_t_norm_list.append(func_w_t_norm)

    # histogram of the distribution of the number of updates
    plt.figure(figsize=(10, 6))
    plt.hist(updates_list, bins=30, color='blue', alpha=0.7)
    plt.title('Distribution of Updates in PLA')
    plt.xlabel('Number of Updates')
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.show()

    print(f"Median of updates: {np.median(updates_list)}")
    print(f"Mean of updates: {np.mean(updates_list)}")

    # histogram of the norm of each experiment
    plt.figure(figsize=(10, 6))
    for w_t in func_w_t_norm_list:
        plt.plot(w_t, alpha=0.2, color='blue')  # Superpose the 1000 functions

    plt.title(f'Norm of Weight Vector (∥w_t∥) as a Function of t')
    plt.xlabel('t (Number of Updates)')
    plt.ylabel('∥w_t∥ (Norm of Weight Vector)')
    plt.grid(True)
    plt.show()


if __name__ == '__main__':
    data, labels = load_libsvm_data('./rcv1_train.binary')
    data, labels = data.to(device), labels.to(device)

    experiments(data, labels)

# Example tensor
w = torch.tensor([3.0, 4.0])

# Calculate the norm
norm_w = torch.norm(w)

# Check the type of the result
print(type(norm_w))  # <class 'torch.Tensor'>

# Convert the norm to a Python float
norm_float = norm_w.item()
print(norm_float)    # 5.0
print(type(norm_float))  # <class 'float'>

# Convert the norm to an integer (if needed)
norm_int = int(norm_float)
print(norm_int)    # 5
print(type(norm_int))  # <class 'int'>